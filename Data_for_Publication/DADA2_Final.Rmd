---
title: "Final_Code_DADA2_SILVA_Pruning"
output: html_notebook
---

# Experimental set up and background 

# Evaluating the Impact of Antibiotic Treatments on the Microbiome of Orbicella faveolata Affected by Caribbean Yellow-Band Disease (CYBD)

## Experimental Summary

O.faveolata microbiome samples were taken at two time points two days appart. The first time point occurred before any treatments were applied and there were the following:

Pre-Treatment:

Diseased colonies with two CYBD lesions - tissue samples taken ~ 10cm from the lesion into the apparently healthy tissue

one lesion designated for amoxicilin treatment and the other designated as untreated 

Healthy control colonies showing no signs of disease - sample of healthy microbiome



For treated lesions a firebreak was made around the lesion to separate it from apparently healthy tissue and amoxicillin was administered in the firebreak 


Post-Treatment: 

After treatment occurred 

Diseased colonies with 2 CYBD lesions - one lesion was treated with amoxicilin as stated above and the other left untreated. Microbiome samples were taken from each of the two lesions and ~ 10cm into the surrounding healthy tissue.

Healthy control colonies showing now signs of disease were also sampled


## Setup
AHT - apparently healthy tissue which was taken ~ 10cm from the lesion on a diseased colony - this tissue appears unaffected by disease via visual observation



Pre-Treatment                                                                               Post-Treatment

Healthy control x5 colonies                                                      Healthy control x5 colonies    


Diseased colony (2 lesions on each colony)                                       Diseased colony (2 lesions on each colony)


*x5 colonies*                                                                    *x5 colonies* 
Lesion 1) AHT not designated for treatment                                       Lesion 1) untreated AHT 
                                                                                 Lesion 1) untreated lesion
                                                                                 
Lesion 2) AHT pre treatment with amoxicilin                                      Lesion 2) AHT post treatment with amoxicilin 
                                                                                 Lesion 2) Lesion post treatment with amoxicilin 
 
 
 
 
 
 
 
# **DADA2 PIPELINE + SILVA DATABASE**
- From : 
R note book file : DADA2Silva_STX_mrdna.Rmd
title: "DADA2 and Silva pipeline for STX 2020 Treatment Microbiome with MR DNA"
original script authors: Dr. Sara Williams and Renee Grambihler, Summer 2021

Input: 
  fastq files from Mr DNA
  STX sample list June 2020.csv : metadata for STX microbiome
  
Output: 
  mergers.rds : RDS object, merged paired end reads
  stall.rds : RDS object, sequence table from merged reads
  reads_lost.txt : text files, summary table after removing chimeric reads
  seqtab.rds : RDS object, chimera-free ASV table
  ps.rds : phyloseq object of OTU and Tax tables, no species level
  ps_sp.rds : phyloseq object of OTU and Tax tables, with species level
  ps_sp_full.rds : phyloseq object of OTU, Tax table, and Sample Data -- with species level 


### Load packages
```{r load libraries, message=FALSE, include=FALSE}
library(ggplot2)
library(dplyr)
library(gridExtra)
library(tidyverse)
### these are from bioconductor
library(dada2)
library(phyloseq)
library(DECIPHER)
library(phangorn)
```

### Set the seed.
```{r set seed}
set.seed(100)
```

### Set path
```{r Set path to folder with all fastq files}
path <- "/Users/renee/Documents/GitHub/STX_Treatment_Microbiome/mr_dna_pipeline/demux"

#make sure it worked correctly
list.files(path)[1:4]

```

### Filter and Trim Steps
### Reads and files set-up
```{r sets it up so that forward and reverse reads are in the same order and you can get a list of file paths for all samples.}

# Sort ensures forward/reverse reads are in same order
fnFs <- sort(list.files(path, pattern="_R1_001.fastq.gz"))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq.gz"))

# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
# forward names
sample.names <- sapply(strsplit(basename(fnFs), "_L"), `[`, 1) 
# reverse names
sample.namesR <- sapply(strsplit(basename(fnRs), "_L"), `[`, 1)

#check to make sure that there are no duplicates
if(!identical(sample.names, sample.namesR)) stop("Forward and reverse files do not match.")
duplicated(sample.names) #sanity check
# Specify the full path to the fnFs (forward reads) and fnRs (reverse reads)
fnFs <- file.path(path, fnFs)
fnRs <- file.path(path, fnRs)
fnFs[1:2]
fnRs[1:2]
```


#### Plot quality profiles
Plot the visual summary of the distribution of quality scores as a function of sequence position for the fastq files
```{r Forward reads}
plotQualityProfile(fnFs[1:3])
```


```{r Reverse reads}
plotQualityProfile(fnRs[1:3])
```


### Filter and Trim
This chunk takes some time to run. It is a computer-time-extensive step. Estimate it taking about a minute per sample. 
```{r filtering and trimming}
# Place filtered files in filtered/ subdirectory; these are empty until the function is run
# forwards: 
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
# reverses:
filtRs <- file.path(path, "filtered", paste0(sample.namesR, "_R_filt.fastq.gz"))

# sanity check to make sure that there are no doubles
duplicated(filtFs) 

# name filtered files
names(filtFs) <- sample.names
names(filtRs) <- sample.namesR

# filter and trim step: 
# fowards, filtered forwards, reverses, & filtered reverses
# trunclen decided from the quality profiles
# on windows multithread =FALSE; on Mac, use the multithread option, it goes faster
out2 <- filterAndTrim(fnFs, filtFs, fnRs, filtRs,
                      truncLen=c(190,190), 
                      maxN=0, 
                      maxEE=c(2,2), 
                      truncQ=2, 
                      rm.phix=TRUE, 
                      compress=TRUE,
                      multithread=TRUE, 
                      matchIDs=TRUE) 

head(out2)
#the percent of reads making it through the filter and trim step:
colSums(out2)[2]/colSums(out2)[1] 

```

#### Estimate errors
This step takes a very very long time. Set multithread=TRUE when working on a mac.
```{r Estimating errors}
# Learn forward error rates
errF <- learnErrors(filtFs, nbases=1e8, multithread=TRUE)

# Learn reverse error rates
errR <- learnErrors(filtRs, nbases=1e8, multithread=TRUE)

# Visualize these error rates
plotErrors(errF, nominalQ=TRUE)
plotErrors(errR, nominalQ=TRUE)
```


### The DADA2 step
```{r Sample inference and merger of paired-end reads}
#set up place for mergers
mergers <- vector("list", length(sample.names))
names(mergers) <- sample.names

mergers

for(sam in sample.names) {
  cat("Processing:", sam, "\n")
  
  # de-replicate forwards
  derepF <- derepFastq(filtFs[[sam]])
  # core sample interference algorithm
  ddF <- dada(derepF, err=errF, multithread=TRUE)
  
  # de-repicate reverses
  derepR <- derepFastq(filtRs[[sam]])
  # core sample interference algorithm
  ddR <- dada(derepR, err=errR, multithread=TRUE) 
  
  # Merge paired end reads
  merger <- mergePairs(ddF, derepF, ddR, derepR)
  mergers[[sam]] <- merger
}

# save mergers as RDS object in case something crashes
saveRDS(mergers,"mergers.rds")
```

#### Some more filtering post-DADA2
```{r Post-DADA2 filtering}
# remove derepF and derepR from R environment to save memory
rm(derepF); rm(derepR)

# Make sequence table from merged reads
# seqtab; Normal to get warning message saying the sequences being tabled vary in length
st.all <- makeSequenceTable(mergers)
saveRDS(st.all,"stall.rds")

# Inspect distribution of read lengths
table(nchar(getSequences(stall)))
hist(nchar(getSequences(stall)), breaks = 100)

# Remove any ASVs that are considerably off target length
seqtab_trimmed <- stall[,nchar(colnames(stall)) %in% seq(250,255)]

seq.data <- as.data.frame(seqtab_trimmed)


# Inspect distribution of read lengths after removal of off-target reads
table(nchar(getSequences(seqtab_trimmed)))
hist(nchar(getSequences(seqtab_trimmed)))



# Remove chimeric sequences
seqtab <- removeBimeraDenovo(seqtab_trimmed, method="consensus", multithread=TRUE, verbose = T) #Identified 

# Number of chimeras removed: 22,060,073 initially; 1,714,129 after MRDNA trimming
sum(stall)-sum(seqtab)
# Percent of sequences remaining: 92.46 after MRDNA trimming
sum(seqtab)/sum(stall)

# track reads through the pipeline: 
getN <- function(x) sum(getUniques(x))
summary_tab <- data.frame(row.names=sample.names, dada2_input=out2[,1],filtered=out2[,2], nonchim=rowSums(seqtab),final_perc_reads_retained=round(rowSums(seqtab)/out2[,1]*100, 1))
#print summary table
summary_tab

#save summary table
write.table(summary_tab, file = "reads_lost.txt", sep="\t") 

# Save chimera-free ASV table as downstream tasks may cause R to crash
saveRDS(seqtab, "seqtab.rds")
```

#reads lost as an excel so turn it into a data frame 
```{r}

reads_lost <-read.csv("reads_lost.csv")

```



### Assign taxonomy using Silva reference database
The dada2 package GitHub maintains the most updated versions of the [Silva databases.](https://benjjneb.github.io/dada2/training.html). 
```{r Assigning taxonomy via Silva}
seqtab <- readRDS("seqtab.rds")

tax_silva <- assignTaxonomy(seqtab, "/Users/renee/Documents/GitHub/STX_Treatment_Microbiome/qiime_pipeline/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)

# Assign taxonomy based on silva reference database at species (100%) level
silva_sp <- addSpecies(tax_silva, "/Users/renee/Documents/GitHub/STX_Treatment_Microbiome/qiime_pipeline/silva_species_assignment_v138.1.fa.gz")

# Export sequence table with genus and species assignments as phyloseq objects
ps <- phyloseq(otu_table(seqtab, taxa_are_rows=FALSE), tax_table(tax_silva))
ps_sp <- phyloseq(otu_table(seqtab, taxa_are_rows=FALSE), tax_table(silva_sp))

#originally, sequences were the taxa names
seqs.ps<-taxa_names(ps_sp)

#change taxa names to ASVs
taxa_names(ps_sp) <- paste0("ASV", seq(ntaxa(ps_sp)))

#save a file of the taxa table with ASVs and sequences
taxtab.seqs<-cbind(data.frame(tax_table(ps_sp)), seqs.ps)
write.csv(taxtab.seqs,"taxatable_withsequences.csv")

# Save as RDS objects
saveRDS(ps, file = "ps.rds") #does not have species level
saveRDS(ps_sp, file = "ps_sp.rds") #with species level and ASV labeling

```

### Add Sample Data to phyloseq object
```{r Clean metadata and add sample data to ps_sp}
# read in Metadata/Sample Data and convert to dataframe
samdf <- read.csv("~/Documents/GitHub/STX_Treatment_Microbiome/mr_dna_pipeline/STX sample list June 2020.csv", stringsAsFactors = FALSE)

# Editing metadata csv  and creating Sample.ID column so that the row names used will match with the sample names in the phyloseq object (ps) and the sample data can be combined/used as the sam_data with the phyloseq object 
samdf$Additional.labeling[is.na(samdf$Additional.labeling)] <- "pre"
samdf$Additional.labeling <- gsub('"', "", samdf$Additional.labeling)
samdf$Sample.ID <- paste(samdf$Sample.., samdf$Treatment, samdf$Additional.labeling)

samdf$Sample.ID <- gsub("control ", "", samdf$Sample.ID)
samdf$Sample.ID <- gsub("006B ", "006B", samdf$Sample.ID)
samdf$Sample.ID <- gsub("les", "lesion", samdf$Sample.ID)
samdf$Sample.ID <- gsub("amoxicillin", "amox", samdf$Sample.ID)
samdf$Sample.ID <- gsub(" ", ".", samdf$Sample.ID)

# making Sample.ID row into the row names for df 
row.names(samdf) <- samdf$Sample.ID 

samdf$Treatment.type <- paste(samdf$Treatment)
samdf$Treatment.type <- gsub("amoxicillin", "treated", samdf$Treatment.type)
samdf$Treatment.type <- gsub("gentamicin", "treated", samdf$Treatment.type)

samdf[samdf$Treatment == "untreated" & samdf$Sample.. %in% c("001B", "004B", "006B "), 6] <- "gentamicin"
samdf[samdf$Treatment == "untreated" & samdf$Sample.. %in% c("002B", "003B", "005B", "007B", "008B"), 6] <- "amoxicillin" 

# turning df into sample data 
df = as(sample_data(samdf), "data.frame") 

# editing the sample names in the phyloseq object so that they match the sample names in df before combining df with ps
sample_names(ps) <- gsub('_S1', "", sample_names(ps))

sample_data(ps) <- df
sample_data(ps)

saveRDS(ps, "ps_sp_full.rds")
```






# ** PRUNING **

```{r Loading packages and set working directory}
#set your working directory OR the nice thing about R notebooks is that your wd is automatically the folder where your code is located.
#setwd("~/Mote_Coral_Fall2020/microbes_pipeline")
library(phyloseq)
library(ggplot2)
library(vegan)
#... add any other standard packages.
```


### get the ps object
```{r}
ps<-readRDS("ps_sp_DADA2Silva.rds")
ps
```


### Some standard filter/prune steps before you start the rest of your analyses:
```{r}
#get rid of 0 taxa
ps
ps_clean <- prune_taxa(taxa_sums(ps) > 0, ps)
any(sample_sums(ps_clean) == 0) #reports FALSE if no zero taxa
ps_clean
#get rid of taxa in less than 4 samples
ps_clean<- prune_taxa(taxa_sums(ps_clean) > 4, ps_clean)
ps_clean

# how many reads 
sum(sample_sums(ps_clean))

# 9478 ASVs 21032447 reads left

#get rid of common contaminants
ps.filt<-subset_taxa(ps_clean, (Order!="Chloroplast") | is.na(Order)) 
sum(sample_sums(ps.filt))


#9022 ASVs 18073749 reads retained 


ps.filt<-subset_taxa(ps.filt, (Family!="Mitochondria") | is.na(Family)) 
ps.filt
sum(sample_sums(ps.filt))

#8819 ASVs retained 17746699 reads 
saveRDS(ps.filt,"ps_filtered_STXtreatment.rds")
```

# Merging the phyloseq

```{r reading in the phyloseq of the asv and tax table *there is chloroplast*}
#this phyloseq object should be the asv and the tax table but not the sample data 
ps_original <- readRDS("ps_filtered_STXtreatment.rds")

#Note there should be 58 samples in the otu table 
```


```{r reading in the csv}
#read in the csv of the sample data 

samdf <- read.csv("Copy of STX sample list June 2020_modified_APL_Jan_15.csv", row.names = 1)

samdf

#Note there should be 58 samples loading in 
```
```{r creating a new merged phyloseq with all 3 elements}
#turning sample data into dataframe 
sample.data <- sample_data(samdf)
(sample.data)

ps_sample <- phyloseq(sample.data)
ps_sample

ps<- merge_phyloseq(ps_original, ps_sample)
ps

sample_names(ps_original)
sample_names(ps_sample)

ps
tax_table(ps)
sample_names(ps)
otu_table(ps)


####This is the new merged phyloseq object that has all three important components - double check because this is critical to have done correctly ####
```

```{r saving your phyloseq object to your working directory}
saveRDS(ps.filt,"Thesis_filt_Jan_15_Phyloseq.rds")
ps <- readRDS("Thesis_filt_Jan_15_Phyloseq.rds")


```











